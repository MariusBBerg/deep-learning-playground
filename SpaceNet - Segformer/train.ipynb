{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e2f3bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tifs: 1148\n",
      "geojsons: 1148\n",
      "example tif: RGB-PanSharpen_AOI_3_Paris_img10.tif\n",
      "example geo: buildings_AOI_3_Paris_img10.geojson\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re, glob\n",
    "\n",
    "DATA_ROOT = Path(\"AOI_3_Paris_Train\")  # endre\n",
    "RGB_DIR = DATA_ROOT / \"RGB-PanSharpen\"\n",
    "GEO_DIR = DATA_ROOT / \"geojson/buildings\"\n",
    "\n",
    "rgb_tifs = sorted(RGB_DIR.glob(\"*.tif\"))\n",
    "geojsons = sorted(GEO_DIR.glob(\"buildings_AOI_3_Paris_img*.geojson\"))\n",
    "\n",
    "print(\"tifs:\", len(rgb_tifs))\n",
    "print(\"geojsons:\", len(geojsons))\n",
    "print(\"example tif:\", rgb_tifs[0].name)\n",
    "print(\"example geo:\", geojsons[0].name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2bf9741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB-PanSharpen_AOI_3_Paris_img10.tif -> AOI_3_Paris_Train/geojson/buildings/buildings_AOI_3_Paris_img10.geojson\n",
      "RGB-PanSharpen_AOI_3_Paris_img100.tif -> AOI_3_Paris_Train/geojson/buildings/buildings_AOI_3_Paris_img100.geojson\n",
      "RGB-PanSharpen_AOI_3_Paris_img1000.tif -> AOI_3_Paris_Train/geojson/buildings/buildings_AOI_3_Paris_img1000.geojson\n",
      "RGB-PanSharpen_AOI_3_Paris_img1001.tif -> AOI_3_Paris_Train/geojson/buildings/buildings_AOI_3_Paris_img1001.geojson\n",
      "RGB-PanSharpen_AOI_3_Paris_img1003.tif -> AOI_3_Paris_Train/geojson/buildings/buildings_AOI_3_Paris_img1003.geojson\n"
     ]
    }
   ],
   "source": [
    "def extract_img_id(name: str) -> str:\n",
    "    # finner \"img380\" etc\n",
    "    m = re.search(r\"(img\\d+)\", name)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Could not find img### in: {name}\")\n",
    "    return m.group(1)\n",
    "\n",
    "geo_by_img = {extract_img_id(p.name): p for p in geojsons}\n",
    "\n",
    "# test\n",
    "for p in rgb_tifs[:5]:\n",
    "    img_id = extract_img_id(p.name)\n",
    "    print(p.name, \"->\", geo_by_img.get(img_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7927c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tifs: 100%|██████████| 1148/1148 [01:46<00:00, 10.73it/s]\n",
      "tifs: 100%|██████████| 1148/1148 [01:46<00:00, 10.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Total rows appended: 4592\n",
      "tiles: 4592 train: 3660 val: 932\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from rasterio.features import rasterize\n",
    "import geopandas as gpd\n",
    "import cv2\n",
    "from shapely.geometry import box\n",
    "import hashlib\n",
    "\n",
    "OUT = Path(\"./tiles_paris_rgb\")\n",
    "(train_img, train_msk) = (OUT/\"train/images\", OUT/\"train/masks\")\n",
    "(val_img, val_msk)     = (OUT/\"val/images\",   OUT/\"val/masks\")\n",
    "for p in [train_img, train_msk, val_img, val_msk]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TILE = 512\n",
    "STRIDE = 384\n",
    "\n",
    "def tile_starts(full, tile, stride):\n",
    "    if full <= tile:\n",
    "        return [0]\n",
    "    starts = list(range(0, full - tile + 1, stride))\n",
    "    last = full - tile\n",
    "    if starts[-1] != last:\n",
    "        starts.append(last)\n",
    "    return starts\n",
    "\n",
    "def is_val_scene(img_id, frac=0.2):\n",
    "    h = int(hashlib.md5(img_id.encode()).hexdigest(), 16)\n",
    "    return (h % 1000) < int(frac * 1000)\n",
    "\n",
    "def write_png(path, arr):\n",
    "    cv2.imwrite(str(path), cv2.cvtColor(arr, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def to_uint8_percentile_nonzero(rgb_chw, p_low=2, p_high=98, min_range=50, fallback_hi=1200):\n",
    "    \"\"\"\n",
    "    rgb_chw: (3,H,W) uint16/float\n",
    "    - bruker kun nonzero piksler per kanal for percentiler\n",
    "    - hvis for få gyldige piksler eller hi-lo for liten -> fallback til [0..fallback_hi]\n",
    "    - holder nodata (alle kanaler 0) som 0 i output\n",
    "    \"\"\"\n",
    "    x = rgb_chw.astype(np.float32)\n",
    "    out = np.empty_like(x, dtype=np.float32)\n",
    "\n",
    "    nodata = (x[0] == 0) & (x[1] == 0) & (x[2] == 0)\n",
    "\n",
    "    for c in range(3):\n",
    "        vals = x[c].ravel()\n",
    "        vals = vals[vals > 0]  # ignorer 0 (nodata/black)\n",
    "\n",
    "        if vals.size < 1000:\n",
    "            lo, hi = 0.0, float(fallback_hi)\n",
    "        else:\n",
    "            lo = np.percentile(vals, p_low)\n",
    "            hi = np.percentile(vals, p_high)\n",
    "            if (hi - lo) < min_range:\n",
    "                lo, hi = 0.0, float(fallback_hi)\n",
    "\n",
    "        out[c] = (x[c] - lo) / (hi - lo + 1e-6)\n",
    "\n",
    "    out = np.clip(out, 0, 1)\n",
    "    out = (out * 255).astype(np.uint8)\n",
    "\n",
    "    # bevar nodata som svart\n",
    "    out[:, nodata] = 0\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def rasterize_mask(polys_gdf, win_transform, h, w):\n",
    "    if len(polys_gdf) == 0:\n",
    "        return np.zeros((h, w), dtype=np.uint8)\n",
    "    shapes = [(geom, 1) for geom in polys_gdf.geometry]\n",
    "    return rasterize(\n",
    "        shapes,\n",
    "        out_shape=(h, w),\n",
    "        transform=win_transform,\n",
    "        fill=0,\n",
    "        dtype=np.uint8,\n",
    "        all_touched=False,\n",
    "    )\n",
    "\n",
    "rows = []\n",
    "\n",
    "for tif in tqdm(rgb_tifs, desc=\"tifs\"):\n",
    "    img_id = extract_img_id(tif.name)\n",
    "    geo_path = geo_by_img.get(img_id)\n",
    "    if geo_path is None:\n",
    "        print(\"WARN: no geojson for\", tif.name, \"img_id\", img_id)\n",
    "        continue\n",
    "\n",
    "    with rasterio.open(tif) as src:\n",
    "        W, H = src.width, src.height\n",
    "        img_crs = src.crs\n",
    "\n",
    "        gdf = gpd.read_file(geo_path)\n",
    "        if gdf.crs != img_crs:\n",
    "            gdf = gdf.to_crs(img_crs)\n",
    "        _ = gdf.sindex\n",
    "\n",
    "        xs = tile_starts(W, TILE, STRIDE)\n",
    "        ys = tile_starts(H, TILE, STRIDE)\n",
    "\n",
    "        scene_val = is_val_scene(img_id, frac=0.2)\n",
    "\n",
    "        for y0 in ys:\n",
    "            for x0 in xs:\n",
    "                win = Window(x0, y0, TILE, TILE)\n",
    "                win_transform = rasterio.windows.transform(win, src.transform)\n",
    "\n",
    "                left, bottom, right, top = rasterio.windows.bounds(win, src.transform)\n",
    "                cand_idx = list(gdf.sindex.intersection((left, bottom, right, top)))\n",
    "                cand = gdf.iloc[cand_idx]\n",
    "\n",
    "                bbox_geom = box(left, bottom, right, top)\n",
    "                cand = cand[cand.intersects(bbox_geom)]\n",
    "\n",
    "                rgb = src.read([1,2,3], window=win)      # (3,H,W) uint16\n",
    "                rgb = to_uint8_percentile_nonzero(rgb)          # (3,H,W) uint8\n",
    "                rgb = np.transpose(rgb, (1,2,0))        # (H,W,3)\n",
    "\n",
    "                msk = rasterize_mask(cand, win_transform, TILE, TILE)\n",
    "\n",
    "                split = \"val\" if scene_val else \"train\"\n",
    "                base = f\"{Path(tif).stem}_x{x0}_y{y0}\"\n",
    "\n",
    "                if split == \"train\":\n",
    "                    write_png(train_img / f\"{base}.png\", rgb)\n",
    "                    cv2.imwrite(str(train_msk / f\"{base}.png\"), (msk*255).astype(np.uint8))\n",
    "                else:\n",
    "                    write_png(val_img / f\"{base}.png\", rgb)\n",
    "                    cv2.imwrite(str(val_msk / f\"{base}.png\"), (msk*255).astype(np.uint8))\n",
    "\n",
    "                rows.append({\"id\": base, \"tif\": tif.name, \"img_id\": img_id, \"x0\": x0, \"y0\": y0, \"split\": split})\n",
    "\n",
    "print(f\"DEBUG: Total rows appended: {len(rows)}\")\n",
    "\n",
    "meta = pd.DataFrame(rows)\n",
    "meta.to_csv(OUT/\"tiles_meta.csv\", index=False)\n",
    "\n",
    "print(\n",
    "    \"tiles:\", len(meta),\n",
    "    \"train:\", (meta[\"split\"] == \"train\").sum(),\n",
    "    \"val:\",   (meta[\"split\"] == \"val\").sum()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db79e7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype: uint16\n",
      "min/max per band: [(np.uint16(0), np.uint16(1525)), (np.uint16(0), np.uint16(1772)), (np.uint16(0), np.uint16(1202))]\n",
      "p2/p98 per band: [(np.float64(0.0), np.float64(807.0)), (np.float64(0.0), np.float64(890.0)), (np.float64(0.0), np.float64(610.0))]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "meta = pd.read_csv(\"./tiles_vegas_rgb/tiles_meta.csv\")\n",
    "print(meta.groupby(\"img_id\").size().describe())\n",
    "print(meta.groupby(\"img_id\").size().head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7b089b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "class BuildingsTiles(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_dir, msk_dir, augment=None):\n",
    "        self.img_paths = sorted(Path(img_dir).glob(\"*.png\"))\n",
    "        self.msk_dir = Path(msk_dir)\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self): return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        p = self.img_paths[i]\n",
    "        img = np.array(Image.open(p).convert(\"RGB\"))\n",
    "        msk = np.array(Image.open(self.msk_dir / p.name))\n",
    "        msk = (msk > 0).astype(np.uint8)\n",
    "\n",
    "        if self.augment:\n",
    "            out = self.augment(image=img, mask=msk)\n",
    "            img, msk = out[\"image\"], out[\"mask\"]\n",
    "\n",
    "        img = torch.from_numpy(img).permute(2,0,1).float() / 255.0\n",
    "        msk = torch.from_numpy(msk).long()  # (H,W) class id 0/1\n",
    "        return img, msk\n",
    "\n",
    "train_aug = A.Compose([\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "])\n",
    "\n",
    "train_ds = BuildingsTiles(\"./tiles_vegas_rgb/train/images\", \"./tiles_vegas_rgb/train/masks\", train_aug)\n",
    "val_ds   = BuildingsTiles(\"./tiles_vegas_rgb/val/images\",   \"./tiles_vegas_rgb/val/masks\",   None)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=16, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "print(len(train_ds), len(val_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fab5bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "    \"nvidia/segformer-b2-finetuned-ade-512-512\",\n",
    "    num_labels=2,\n",
    "    ignore_mismatched_sizes=True,\n",
    ").to(device)\n",
    "\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=3e-5, weight_decay=1e-2)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n",
    "\n",
    "def iou_from_logits(logits, target):\n",
    "    # logits: (B,2,H,W), target: (B,H,W)\n",
    "    pred = logits.argmax(1)\n",
    "    inter = ((pred==1) & (target==1)).sum().item()\n",
    "    union = ((pred==1) | (target==1)).sum().item()\n",
    "    return inter / (union + 1e-6)\n",
    "\n",
    "best = -1\n",
    "for epoch in range(1, 6):\n",
    "    model.train()\n",
    "    for imgs, masks in train_loader:\n",
    "        imgs, masks = imgs.to(device), masks.to(device)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
    "            out = model(pixel_values=imgs)\n",
    "            logits = F.interpolate(out.logits, size=masks.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "            loss = F.cross_entropy(logits, masks)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "\n",
    "    model.eval()\n",
    "    ious = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks in val_loader:\n",
    "            imgs, masks = imgs.to(device), masks.to(device)\n",
    "            out = model(pixel_values=imgs)\n",
    "            logits = F.interpolate(out.logits, size=masks.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "            ious.append(iou_from_logits(logits, masks))\n",
    "\n",
    "    miou = float(np.mean(ious))\n",
    "    print(f\"epoch {epoch} | val IoU={miou:.4f}\")\n",
    "    if miou > best:\n",
    "        best = miou\n",
    "        torch.save(model.state_dict(), \"best_segformer_vegas.pth\")\n",
    "        print(\"saved best\")\n",
    "    #save latest model with optimizer state\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': opt.state_dict(),\n",
    "        }, \"latest_segformer_vegas.pth\")\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacenet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
